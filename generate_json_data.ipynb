{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kaldi_io\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取feats.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_map = {}\n",
    "with open(\"/home/meichaoyang/dataset/500C/feats.scp\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        feats_map[data[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/meichaoyang/dataset/500C//_fbank/raw_fbank_500C.1.ark:106521'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_map[\"T0055G0002S0007\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_map = {}\n",
    "with open('/home/meichaoyang/dataset/500C/corpus.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        corpus_txt = re.sub(r\"([.!?。！，？、 \\[\\],，])\", r\"\", data[1])\n",
    "        corpus_map[data[0]] = corpus_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'国内哪些大学有韩语专业'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_map[\"T0055G0002S0081\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "import re\n",
    "# string = '我要把你卸载掉'\n",
    "# re.findall(r'.{1}', string)\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in re.findall(r'.{1}', sentence):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?。！，？、 \\[\\],，])\", r\" \\1\", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1):\n",
    "    print(\"Reading lines...\")\n",
    "    lang = Lang(lang1)\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('/home/meichaoyang/dataset/500C/corpus.txt', \"r\").\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    for l in lines:\n",
    "        s = l.split(\"\\t\")\n",
    "        lang.addSentence(normalizeString(s[1]))\n",
    "\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "lang = readLangs(\"ZH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4378\n",
      "俾\n",
      "4378\n",
      "90\n",
      "108258\n"
     ]
    }
   ],
   "source": [
    "print(len(lang.index2word))\n",
    "print(lang.index2word[4377])\n",
    "print(lang.n_words)\n",
    "print(lang.word2index[\" \"])\n",
    "print(lang.word2count[\" \"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备json数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {}\n",
    "utts = json_data[\"utts\"] = {}\n",
    "dic = json_data[\"dic\"] = {}\n",
    "for i in range(lang.n_words):\n",
    "    dic[lang.index2word[i]] = i\n",
    "    lang.index2word[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(feats_map.keys())\n",
    "for utt in keys:\n",
    "    utts[utt] = {}\n",
    "    utts[utt][\"input\"] = {}\n",
    "    utts[utt][\"input\"][\"feat\"] = feats_map[utt]\n",
    "    utts[utt][\"input\"][\"shape\"] = list(kaldi_io.read_mat(feats_map[utt]).shape)\n",
    "    utts[utt][\"output\"] = {}\n",
    "    utts[utt][\"output\"][\"text\"] = corpus_map[utt]\n",
    "    tokenid = [lang.word2index[ch.lower()] for ch in corpus_map[utt]]\n",
    "    utts[utt][\"output\"][\"tokenid\"] = tokenid\n",
    "    utts[utt][\"output\"][\"shape\"] = [len(tokenid), lang.n_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = kaldi_io.read_mat(feats_map[\"T0055G0002S0006\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 80)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:a.shape[0]//4*4].shape\n",
    "# a.shape[0]//4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '再给我讲个笑话好吗',\n",
       " 'tokenid': [39, 40, 20, 41, 42, 43, 44, 45, 46],\n",
       " 'shape': [9, 4378]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utts[\"T0055G0002S0007\"][\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写入json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4378"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data[\"dic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.9022, 10.2037, 11.9769,  ..., 14.1464, 14.7736, 14.0025],\n",
       "        [ 6.5292,  7.8970,  9.2169,  ..., 14.2464, 13.6531, 13.0010],\n",
       "        [ 7.6166,  9.3611, 11.2072,  ..., 13.2118, 13.5785, 12.3967],\n",
       "        ...,\n",
       "        [ 8.5451,  9.9356,  9.8816,  ..., 13.6333, 14.6908, 13.7032],\n",
       "        [ 8.5094, 10.2420, 11.1217,  ..., 12.9736, 13.7464, 13.2024],\n",
       "        [ 7.5809,  9.3611, 10.9934,  ..., 13.3218, 14.2075, 13.4787]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = json_data[\"utts\"][\"T0055G0002S0007\"][\"input\"]\n",
    "torch.tensor(kaldi_io.read_mat(input1[\"feat\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'feat': '/home/meichaoyang/dataset/500C//_fbank/raw_fbank_500C.1.ark:106521',\n",
       "  'shape': [232, 80]},\n",
       " 'output': {'text': '再给我讲个笑话好吗',\n",
       "  'tokenid': [39, 40, 20, 41, 42, 43, 44, 45, 46],\n",
       "  'shape': [9, 4378]}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[\"utts\"][\"T0055G0002S0007\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Hello, Runoob\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Hello, Runoob\\\\n'\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
